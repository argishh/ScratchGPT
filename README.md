ScratchGPT is a GPT model built from scratch using theories based on paper titled **'Attention is all you need'**. This paper introduced the Transformer architecture.

The dataset used here is Tiny Shakespeare dataset, which contains all of Shakespeare's plays combined into a single file.

Concepts implemented - Transformer Architecture, Self-attention mechanism (decoder-attention), multi-headed self attention, residual connections, layernorm.

YouTube video link -
[Andrej Karapathy tutorial](https://www.youtube.com/watch?v=kCc8FmEb1nY)

<br>
<br>

p.s. Thank You for an amazing tutorial [@AndrejKarpathy](https://www.youtube.com/@AndrejKarpathy)
